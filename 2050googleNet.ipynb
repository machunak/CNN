{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z65ZsRDQYQ4j"
      },
      "outputs": [],
      "source": [
        "# /content/drive/MyDrive/age.zip\n",
        "!mkdir dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/age.zip -d dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex4NfENoZLxb",
        "outputId": "261eec73-b0de-4173-9b57-ef613b6a10b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/age.zip\n",
            "   creating: dataset/fifties/\n",
            "  inflating: dataset/fifties/fifties_actor-001.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-002.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-003.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-004.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-005.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-006.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-007.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-008.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-009.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-010.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-011.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-012.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-013.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-014.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-015.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-016.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-017.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-018.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-019.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-020.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-021.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-022.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-023.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-024.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-025.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-026.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-027.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-028.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-029.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-030.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-031.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-032.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-033.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-034.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-035.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-036.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-037.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-038.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-039.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-040.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-041.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-042.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-043.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-044.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-045.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-046.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-047.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-048.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-049.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-050.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-051.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-052.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-053.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-054.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-055.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-056.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-057.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-058.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-059.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-060.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-061.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-062.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-063.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-064.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-065.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-066.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-067.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-068.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-069.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-070.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-071.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-072.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-073.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-074.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-075.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-076.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-077.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-078.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-079.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-080.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-081.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-082.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-083.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-084.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-085.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-086.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-087.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-088.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-089.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-090.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-091.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-092.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-093.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-094.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-095.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-096.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-097.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-098.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-099.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-100.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-101.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-102.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-103.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-104.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-105.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-106.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-107.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-108.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-109.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-110.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-111.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-112.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-113.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-114.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-115.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-116.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-117.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-118.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-119.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-120.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-121.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-122.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-123.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-124.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-125.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-126.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-127.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-128.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-129.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-130.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-131.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-132.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-133.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-134.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-135.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-136.jpeg  \n",
            "  inflating: dataset/fifties/fifties_actor-137.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-001.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-002.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-003.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-004.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-005.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-006.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-007.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-008.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-009.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-010.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-011.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-012.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-013.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-014.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-015.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-016.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-017.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-018.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-019.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-020.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-021.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-022.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-023.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-024.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-025.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-026.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-027.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-028.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-029.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-030.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-031.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-032.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-033.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-034.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-035.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-036.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-037.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-038.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-039.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-040.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-041.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-042.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-043.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-044.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-045.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-046.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-047.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-048.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-049.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-050.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-051.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-052.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-053.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-054.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-055.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-056.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-057.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-058.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-059.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-060.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-061.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-062.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-063.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-064.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-065.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-066.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-067.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-068.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-069.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-070.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-071.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-072.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-073.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-074.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-075.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-076.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-077.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-078.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-079.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-080.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-081.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-082.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-083.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-084.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-085.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-086.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-087.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-088.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-089.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-090.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-091.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-092.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-093.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-094.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-095.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-096.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-097.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-098.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-099.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-100.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-101.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-102.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-103.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-104.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-105.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-106.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-107.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-108.jpeg  \n",
            "  inflating: dataset/fifties/fifties_man-109.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-001.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-002.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-003.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-004.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-005.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-006.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-007.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-008.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-009.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-010.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-011.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-012.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-013.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-014.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-015.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-016.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-017.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-018.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-019.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-020.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-021.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-022.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-023.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-024.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-025.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-026.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-027.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-028.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-029.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-030.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-031.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-032.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-033.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-034.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-035.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-036.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-037.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-038.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-039.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-040.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-041.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-042.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-043.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-044.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-045.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-046.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-047.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-048.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-049.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-050.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-051.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-052.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-053.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-054.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-055.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-056.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-057.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-058.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-059.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-060.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-061.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-062.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-063.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-064.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-065.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-066.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-067.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-068.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-069.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-070.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-071.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-072.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-073.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-074.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-075.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-076.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-077.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-078.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-079.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-080.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-081.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-082.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-083.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-084.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-085.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-086.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-087.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-088.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-089.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-090.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-091.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-092.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-093.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-094.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-095.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-096.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-097.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-098.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-099.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-100.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-101.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-102.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-103.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-104.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-105.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-106.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-107.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-108.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-109.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-110.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-111.jpeg  \n",
            "  inflating: dataset/fifties/fifties_woman-112.jpeg  \n",
            "   creating: dataset/twenties/\n",
            "  inflating: dataset/twenties/twenties_actor-01.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-02.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-03.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-04.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-05.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-06.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-07.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-08.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-09.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-10.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-11.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-12.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-13.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-14.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-15.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-16.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-17.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-18.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-19.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-20.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-21.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-22.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-23.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-24.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-25.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-26.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-27.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-28.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-29.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-30.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-31.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-32.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-33.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-34.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-35.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-36.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-37.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-38.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-39.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-40.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-41.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-42.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-43.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-44.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-45.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-46.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-47.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-48.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-49.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-50.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-51.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-52.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-53.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-54.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-55.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-56.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-57.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-58.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-59.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-60.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-61.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-62.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-63.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-64.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-65.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-66.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-67.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-68.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-69.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-70.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-71.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-72.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-73.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-74.jpeg  \n",
            "  inflating: dataset/twenties/twenties_actor-75.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-01.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-02.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-03.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-04.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-05.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-06.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-07.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-08.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-09.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-10.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-11.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-12.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-13.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-14.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-15.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-16.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-17.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-18.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-19.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-20.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-21.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-22.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-23.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-24.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-25.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-26.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-27.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-28.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-29.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-30.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-31.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-32.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-33.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-34.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-35.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-36.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-37.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-38.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-39.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-40.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-41.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-42.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-43.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-44.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-45.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-46.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-47.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-48.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-49.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-50.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-51.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-52.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-53.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-54.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-55.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-56.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-57.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-58.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-59.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-60.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-61.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-62.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-63.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-64.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-65.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-66.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-67.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-68.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-69.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-70.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-71.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-72.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-73.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-74.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-75.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-76.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-77.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-78.jpeg  \n",
            "  inflating: dataset/twenties/twenties_man-79.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-01.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-02.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-03.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-04.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-05.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-06.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-07.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-08.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-09.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-10.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-11.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-12.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-13.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-14.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-15.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-16.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-17.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-18.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-19.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-20.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-21.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-22.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-23.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-24.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-25.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-26.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-27.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-28.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-29.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-30.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-31.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-32.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-33.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-34.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-35.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-36.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-37.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-38.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-39.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-40.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-41.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-42.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-43.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-44.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-45.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-46.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-47.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-48.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-49.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-50.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-51.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-52.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-53.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-54.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-55.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-56.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-57.jpeg  \n",
            "  inflating: dataset/twenties/twenties_woman-58.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import PIL # python 의 이미지 전처리 라이브러리\n",
        "import glob # 대용량, 대규모 파일을 다룰 때 사용\n",
        "import os # os, path 관련 조작, 변경, 파일 삭제 등\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "dataset_folder_path = '/content/dataset'\n",
        "category_cnt = os.listdir(dataset_folder_path)\n",
        "os.listdir(dataset_folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpW0rtspaDPM",
        "outputId": "6967a2bf-33cf-467f-9a23-776650fefb81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fifties', 'twenties']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# glob.glob(dataset_folder_path+'/*/*')\n",
        "# 파일의 경로+/* 을 입력하면 해당 폴더 하위 경로 상에 있는 모든 파일을\n",
        "# 리스트로 리턴\n",
        "# ex) dataset_folder_path+'/*/*' -> 하위 폴더의 하위 데이터 전체 리턴\n",
        "import numpy as np\n",
        "x = []\n",
        "y = []\n",
        "for label, folder in enumerate(os.listdir(dataset_folder_path)):\n",
        "   # print(dataset_folder_path + '/'+ folder) 좋은 코드가 아님\n",
        "   # print(os.path.join(dataset_folder_path, folder)) # 유지 보수 좋은 코드\n",
        "    folder_full_path = os.path.join(dataset_folder_path, folder)\n",
        "    all_files = glob.glob(folder_full_path + '/*.jpeg')\n",
        "\n",
        "    for idx, file_full_path in enumerate(all_files):\n",
        "        image = PIL.Image.open(file_full_path)\n",
        "        image = image.resize((64, 64))\n",
        "        image = image.convert('RGB')\n",
        "        data = np.asarray(image)\n",
        "        x.append(data)\n",
        "        y.append(label)\n",
        "        if idx % 30 == 0:\n",
        "            print(idx, '/', len(all_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McScyNqgbaiE",
        "outputId": "7d3c732f-1029-4fa2-9849-384eddb1504d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 358\n",
            "30 / 358\n",
            "60 / 358\n",
            "90 / 358\n",
            "120 / 358\n",
            "150 / 358\n",
            "180 / 358\n",
            "210 / 358\n",
            "240 / 358\n",
            "270 / 358\n",
            "300 / 358\n",
            "330 / 358\n",
            "0 / 212\n",
            "30 / 212\n",
            "60 / 212\n",
            "90 / 212\n",
            "120 / 212\n",
            "150 / 212\n",
            "180 / 212\n",
            "210 / 212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "print('카테고리 갯수', np.bincount(y))\n",
        "print('전처리 확인', x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGgFVQ15fTfD",
        "outputId": "f9271eec-aa78-42e5-a825-7dc735dddb2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "카테고리 갯수 [358 212]\n",
            "전처리 확인 (570, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "bmfk4MtqnLd0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개발 팁, 전처리 시간이 너무 오래 걸린다면(데이터 늘어 나서)\n",
        "# xy = (x_train, x_test, y_train, y_test)\n",
        "# np.save('/content/drive/MyDrive/preprocessing_data.npy', xy)\n",
        "# x_train, x_test, y_train, y_test = np.load('/content/drive/MyDrive/preprocessing_data.npy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIbeJHggoSik",
        "outputId": "45477d78-963f-471c-9faf-24c648fe11cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255."
      ],
      "metadata": {
        "id": "jWPh_Sq-oo_s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글넷 실습 (오전에 진행한)\n",
        "# 레즈넷 실습 (다 짜여진 코드) -> finetuning"
      ],
      "metadata": {
        "id": "rDy39KnXpYlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개선의 여지 해상도 수정 ( 전처리 도 수정 해야 함)\n",
        "input_layer = layers.Input(shape = (64,64,3), name='start_layer')\n",
        "\n",
        "# 개선의 여지 conv2d 수정 성능이 매우 잘 나온다면 -모델 다이어트\n",
        "# 성능이 안나온다면 channel 수, 레이어 추가\n",
        "tower_1 = layers.Conv2D(64, kernel_size = (1,1) , padding='same' , activation= 'relu')(input_layer)\n",
        "\n",
        "tower_2 = layers.Conv2D(64, kernel_size = (1,1) , padding='same' , activation= 'relu')(input_layer)\n",
        "tower_2 = layers.Conv2D(64, kernel_size = (3,3) , padding='same' , activation= 'relu')(tower_2)\n",
        "\n",
        "tower_3 = layers.Conv2D(64, kernel_size = (1,1) , padding='same' , activation= 'relu')(input_layer)\n",
        "tower_3 = layers.Conv2D(64, kernel_size = (5,5) , padding='same' , activation= 'relu')(tower_3)\n",
        "\n",
        "tower_4 = layers.MaxPool2D(pool_size=(3,3), strides=(1,1) , padding='same')(input_layer)\n",
        "tower_4 = layers.Conv2D(64, kernel_size=(1,1) , padding='same' , activation='relu')(tower_4)\n",
        "\n",
        "concat_layer = layers.concatenate([tower_1, tower_2,tower_3,tower_4], axis=3)\n",
        "\n",
        "tower_2_1 = layers.Conv2D(120, kernel_size = (1,1) , padding='same' , activation= 'relu')(concat_layer)\n",
        "\n",
        "tower_2_2 = layers.Conv2D(120, kernel_size = (1,1) , padding='same' , activation= 'relu')(concat_layer)\n",
        "tower_2_2 = layers.Conv2D(120, kernel_size = (3,3) , padding='same' , activation= 'relu')(tower_2_2)\n",
        "\n",
        "tower_2_3 = layers.Conv2D(120, kernel_size = (1,1) , padding='same' , activation= 'relu')(concat_layer)\n",
        "tower_2_3 = layers.Conv2D(120, kernel_size = (5,5) , padding='same' , activation= 'relu')(tower_2_3)\n",
        "\n",
        "tower_2_4 = layers.MaxPool2D(pool_size=(3,3), strides=(1,1) , padding='same')(concat_layer)\n",
        "tower_2_4 = layers.Conv2D(120, kernel_size=(1,1) , padding='same' , activation='relu')(tower_2_4)\n",
        "\n",
        "final_concat_layer = layers.concatenate([tower_2_1, tower_2_2,tower_2_3,tower_2_4], axis=3)\n",
        "average_pooling_layer = layers.AveragePooling2D(pool_size=(16,16),strides=(16,16))(final_concat_layer)\n",
        "flat_layer = layers.Flatten()(average_pooling_layer)\n",
        "\n",
        "# 개선의 여지 -  Dense 층 추가\n",
        "output_layer = layers.Dense(1 , activation = 'sigmoid')(flat_layer)\n",
        "\n",
        "google_net_model = models.Model(inputs = input_layer, outputs = output_layer)\n",
        "google_net_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VkLnztWOqch",
        "outputId": "8636592e-95dc-40c7-f423-ed9e043e0f10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " start_layer (InputLayer)    [(None, 64, 64, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 64)           256       ['start_layer[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 64)           256       ['start_layer[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 64, 64, 3)            0         ['start_layer[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 64, 64, 64)           256       ['start_layer[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)           102464    ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)           256       ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 64, 64, 256)          0         ['conv2d[0][0]',              \n",
            "                                                                     'conv2d_2[0][0]',            \n",
            "                                                                     'conv2d_4[0][0]',            \n",
            "                                                                     'conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 120)          30840     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 64, 64, 120)          30840     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 256)          0         ['concatenate[0][0]']         \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 120)          30840     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 120)          129720    ['conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 64, 64, 120)          360120    ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 64, 64, 120)          30840     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 64, 64, 480)          0         ['conv2d_6[0][0]',            \n",
            " )                                                                   'conv2d_8[0][0]',            \n",
            "                                                                     'conv2d_10[0][0]',           \n",
            "                                                                     'conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 4, 4, 480)            0         ['concatenate_1[0][0]']       \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 7680)                 0         ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1)                    7681      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 761297 (2.90 MB)\n",
            "Trainable params: 761297 (2.90 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_net_model.compile(loss='binary_crossentropy',\n",
        "                         optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "f67H5uPEOsdY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_point_path = '/content/drive/MyDrive/ourmodel_checkpoint'\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(check_point_path,\n",
        "                                   monitor='val_loss',\n",
        "                                   save_best_only=True)\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)"
      ],
      "metadata": {
        "id": "iihWAWicOuk_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_net_model.fit(x_train,y_train, batch_size=32,\n",
        "                     epochs=20,\n",
        "                     callbacks=[mc,es],\n",
        "                     validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpiGS7ldOvGC",
        "outputId": "0487aaf9-5cda-4a5a-c650-a97a39ecd797"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 282s 19s/step - loss: 0.6832 - accuracy: 0.5855 - val_loss: 0.6631 - val_accuracy: 0.6491\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 280s 19s/step - loss: 0.6562 - accuracy: 0.6228 - val_loss: 0.6416 - val_accuracy: 0.6404\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 269s 18s/step - loss: 0.6262 - accuracy: 0.6579 - val_loss: 0.7326 - val_accuracy: 0.6404\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 259s 17s/step - loss: 0.6430 - accuracy: 0.6272 - val_loss: 0.6254 - val_accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 262s 18s/step - loss: 0.6043 - accuracy: 0.6776 - val_loss: 0.6344 - val_accuracy: 0.6842\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 265s 18s/step - loss: 0.6021 - accuracy: 0.6930 - val_loss: 0.6138 - val_accuracy: 0.7018\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 267s 18s/step - loss: 0.5796 - accuracy: 0.7018 - val_loss: 0.5933 - val_accuracy: 0.6842\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 270s 18s/step - loss: 0.5452 - accuracy: 0.7215 - val_loss: 0.6092 - val_accuracy: 0.6404\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 267s 18s/step - loss: 0.5254 - accuracy: 0.7237 - val_loss: 0.6308 - val_accuracy: 0.6842\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 266s 18s/step - loss: 0.5344 - accuracy: 0.7127 - val_loss: 0.6004 - val_accuracy: 0.6754\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 264s 18s/step - loss: 0.4941 - accuracy: 0.7281 - val_loss: 0.6206 - val_accuracy: 0.6228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d024820f970>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## our model inference code\n",
        "# inference만 진행 할 시, 가장 위 import library 실행 -> 모델 빌드 하는 부분 실행\n",
        "google_net_model.load_weights('/content/drive/MyDrive/ourmodel_checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TeqR3PjOz-o",
        "outputId": "4b0e34e9-d38c-4f98-9982-fced39232d32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7d02a431ba00>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "8yJYLyqjO0f3",
        "outputId": "f329666a-e556-4e49-f56d-35d4634df839"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3f561a0-dcbb-4b56-aa71-ac81193bb1d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3f561a0-dcbb-4b56-aa71-ac81193bb1d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving twenties_actor-10.jpeg to twenties_actor-10.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = list(f.keys())[0]\n",
        "test_img = PIL.Image.open(file_name)\n",
        "test_img = test_img.resize((64,64))\n",
        "test_img = test_img.convert('RGB')\n",
        "data = np.asarray(test_img)\n",
        "test_image_tensor = np.array([data])\n",
        "test_image_tensor = test_image_tensor / 255.\n",
        "test_image_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nobnqVSNO4a_",
        "outputId": "f9d84ced-2639-47fc-c653-38bf2c249e36"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = google_net_model.predict(test_image_tensor)\n",
        "result[0][0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONRUBeP4O6iw",
        "outputId": "ddbb7626-8af4-4a3c-e953-171255196be3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 316ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2842254"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if result[0][0] > 0.5:\n",
        "    print(f'{result[0][0] * 100} % 확률로 50대.')\n",
        "else:\n",
        "    print(f'{ (1 - result[0][0]) * 100} % 확률로 20대.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jeOdXVNcOhx",
        "outputId": "436462ed-e079-4a6f-ed20-553b8405252e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71.57745957374573 % 확률로 20대.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터\n",
        "# 2. 모델\n",
        "# 3. 하이퍼 파라미터 수정 (우선 순위 최하)"
      ],
      "metadata": {
        "id": "IeGegnFpQ59Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}